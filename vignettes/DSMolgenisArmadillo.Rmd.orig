---
title: "Analyse your data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Analyse your data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, comment = "#>", out.width = "100%",
  fig.width = 7, fig.height = 4, dpi = 150, fig.path = "DSMolgenisArmadillo-",
  message = FALSE, warning = FALSE, error = FALSE
)
```

When you start to use Armadillo as a backend for DataSHIELD you can use the `DSMolgenisArmadillo` package for research purposes.
There is a default workflow in DataSHIELD to do analysis. There are several steps that you need to take:

### Authenticate
The login procedure consists of building a login dataframe and performing the login on the Armadillo server. The important part is to specify the driver. This should be `ArmadilloDriver`. 

We use oauth to authenticate in DataSHIELD.

```{r, authenticate with authentication server}
# Load the necessary packages.
library(dsBaseClient)
library(DSMolgenisArmadillo)

# specify server url
armadillo_url <- "https://armadillo.dev.molgenis.org"

# get token from central authentication server
token <- armadillo.get_token(armadillo_url)
token
# build the login dataframe
builder <- DSI::newDSLoginBuilder()
builder$append(server = "armadillo",
               url = armadillo_url,
               token = token,
               table = "gecko/2_1-core-1_0/nonrep",
               driver = "ArmadilloDriver")

# create loginframe
logindata <- builder$build()
logindata

# login into server
conns <- datashield.login(logins = logindata, assign = FALSE)
```

### Assign data
To work with DataSHIELD you need to be able to query data. You can do this by assigning data in the Armadillo service.

```{r, assigning data}
# assign data in the Armadillo service
datashield.assign.table(conns = conns,
                        table = "gecko/2_1-core-1_0/nonrep",
                        symbol = "D",
                        variables = c("recruit_age", "child_id"))
```

#### Symbol assignment
For each of the tables assigned in the Aramdillo a symbol is created in each of the servers. 
You can remove the symbol from the workspace on the server by executing the following code:

```{r, assign and check symbols}
# list the current symbols
datashield.symbols(conns)
# remove the symbol
datashield.rm(conns = conns, "D")
# list the current symbols without the deleted one
datashield.symbols(conns)
```

#### Assign data using expressions
You can assign values from tables to symbols, but you can use hardcoded expressions as well.

```{r, assign random data to K}
# assign random data to 'K'
datashield.assign.expr(conns = conns, symbol = "K", "c(10,50,100)")
```

```{r, calculate the mean}
# calculate the mean of 'K' to see that the assignment has worked
ds.mean("K", datasources = conns)
```

#### Assign data from tables
When you have assigned symbols in R, you check which tables (`data.frame`'s) are available on the Armadillo.

```{r, assign data using the table assignment method}
# assign the data again
datashield.assign.table(conns = conns, 
                        table = "gecko/2_1-core-1_0/nonrep", 
                        symbol = "core_nonrep")
```

```{r, show columns within the data frame}
# check the columns in the non-repeated data
ds.colnames("core_nonrep", datasources = conns)
```


### Subsetting data
Before you are working with the data you can subset to a specific range of variables you want to use in the set.

```{r, subset the data to the first 3 years}
# assign the repeated data to reshape
datashield.assign.table(conns = conns,
                        table = "gecko/2_1-core-1_0/yearlyrep",
                        symbol = "core_yearlyrep")

# check dimensions of repeatead measures
ds.dim("core_yearlyrep", datasources = conns)

# subset the data to the first 2 years
ds.dataFrameSubset(df.name = 'core_yearlyrep', newobj = 'core_yearlyrep_1_3', V1.name = "core_yearlyrep$age_years", V2.name = "2", Boolean.operator  = '<=') 

# check the columns
ds.colnames("core_yearlyrep_1_3", datasources = conns)

# check dimensions again
ds.dim("core_yearlyrep_1_3", datasources = conns)
```

```{r, strip the redundant columns}
# strip the redundant columns
ds.dataFrame(x = c("core_yearlyrep_1_3$child_id", "core_yearlyrep_1_3$age_years", "core_yearlyrep_1_3$dogs_",  "core_yearlyrep_1_3$cats_",  "core_yearlyrep_1_3$pets_"),
             completeCases = TRUE,
             newobj = "core_yearlyrep_1_3_stripped",
             datasources = conns)
```

### Transform data
In general you need 2 methods to work with data that is stored in long format, the `reshape` and `merge` functions in DataSHIELD. You can reshape data with the Armadillo to transform data from [wide-format to long-format](https://www.theanalysisfactor.com/wide-and-long-data/) and vice versa. 

You can do this using the `ds.reshape` function:

```{r, reshape yearly repeated data}
# reshape the data for the wide-format variables (yearlyrep)
ds.reShape(data.name='core_yearlyrep_1_3_stripped',
           timevar.name = 'age_years',
           idvar.name = 'child_id',
           v.names=c("pets_", "cats_", "dogs_"),
           direction = 'wide',
           newobj = "core_yearlyrep_1_3_wide",
           datasources = conns
)
```

```{r, show columnnames from wide format data}
# show the reshaped columns of the new data frame
ds.colnames("core_yearlyrep_1_3_wide", datasources = conns)
```

When you reshaped and subsetted the data you often need to merge your dataframe with others to get your analysis dataframe. You can do this using the `ds.merge` function:

```{r, merge both data frames into one}
# merge non-repeated table with wide-format repeated table
# make sure the disclosure measure regarding stringshort is set to '100'
ds.merge(x.name = 'core_nonrep',
         y.name = 'core_yearlyrep_1_3_wide',
         by.x.names = 'child_id',
         by.y.names = 'child_id',
         newobj = 'analysis_df',
         datasources = conns
)
```

```{r, check the merged variables}
ds.colnames("analysis_df", datasources = conns)
```

### Save your work
When you finished building your analysis frame you can save it using [workspaces](https://molgenis.github.io/molgenis-r-datashield/articles/workspaces.html)

### Performing analysis
There are a variety of analysis you can perform in DataSHIELD. You can perform basic merthods such as summary statistics and more advanced methods susch as GLM.

#### Simple statistical methods
You execute a summary on the a variable within you analysis frame. It will return summary statistics.

```{r, summarize the data}
ds.summary("analysis_df$pets_.1", datasources = conns)
```

#### Advanced statistical methods
When you finished the analysis dataframe, you can perform the actual analysis. You can use a wide variety of functions. The example below is showing the `glm`. After that you can create a 

```{r, perform the GLM method} 
datashield.assign.table(conns = conns,
                        table = "gecko/1_1-outcome-1_0/nonrep",
                        symbol = "outcome_nonrep")

armadillo_glm <- ds.glm(formula = 'asthma_ever_CHICOS~pets_preg',
        data = 'outcome_nonrep',
        family = 'binomial',
        datasources = conns)
```

Do the meta analysis and install prerequisites.

```{r, install prerequisites for meta analysis}
install.packages("metafor")
```

```{r, meta-analysis}
yi <- c(armadillo_glm$coefficients["pets_preg", "Estimate"])
sei <- c(armadillo_glm$coefficients["pets_preg", "Std. Error"])

res <- metafor::rma(yi, sei = sei)
res
metafor::forest(res, xlab = "OR", transf = exp, refline = 1, slab = c("armadillo_glm"))
```

#### Creating figures
You can directly create figures with the DataSHIELD methods. For example:

```{r, create-a-histogram}
# create histogram
ds.histogram(x = "core_nonrep$coh_country", datasources = conns)
```


```{r, create-a-heatmap}
# create a heatmap
ds.heatmapPlot(x = "analysis_df$pets_.1", y = "analysis_df$dogs_.1", datasources = conns)
```

```{r, logout to clean session}
# logout
datashield.logout(conns)
```


